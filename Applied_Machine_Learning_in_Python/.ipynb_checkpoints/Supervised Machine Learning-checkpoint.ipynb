{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a5fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.95\n",
      "Accuracy of K-NN classifier on test set: 1.00\n",
      "Predicted fruit type for  [[5.5, 2.2, 10, 0.7]]  is  mandarin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\my\\anaconda3\\lib\\site-packages\\sklearn\\base.py:445: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.set_printoptions(precision = 2) # print 옵션 설정 소수점 아래를 고정 값을 정하여 출력 \n",
    "\n",
    "fruits = pd.read_table('fruit_data_with_colors.txt')\n",
    "\n",
    "feature_names = ['height', 'width', 'mass', 'color_score']\n",
    "X_fruits = fruits[feature_names]\n",
    "y_fruits = fruits[\"fruit_label\"]\n",
    "target_names_fruits = ['apple', 'mandarin', 'orange', 'lemon']\n",
    "\n",
    "X_fruits_2d = fruits[['height', 'width']]\n",
    "y_fruits_2d = fruits['fruit_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fruits, y_fruits, random_state=0) # 디폴트로 Train 75 % test 25% \n",
    "\n",
    "\n",
    "# 각 Feature마다 값의 범위가 다르다. 각 Feature의 값을 일정한 범위 또는 규칙에 따르게 하기 위해서 스케일링을 사용\n",
    "# 최소값(Min)과 최대값(Max)을 사용해서 '0~1' 사이의 범위(range)로 데이터를 표준화해주는 '0~1 변환\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_scaled, y_train) # 훈련데이와 훈련라벨에 fit 사용 , knn객체의 내부상태를 업데이트하는 훈련과정 \n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test_scaled, y_test)))\n",
    "\n",
    "example_fruit = [[5.5, 2.2, 10, 0.70]]\n",
    "example_fruit_scaled = scaler.transform(example_fruit)\n",
    "print('Predicted fruit type for ', example_fruit, ' is ', \n",
    "          target_names_fruits[knn.predict(example_fruit_scaled)[0]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7aa48",
   "metadata": {},
   "source": [
    "모델은 연구되거나, 예측되는 하나 이상의 입력변수와 출벽변수 사이의 관계를 표현하는 특정 수학적 또는 계산적 설명     \n",
    "통계 입력변수를 독립변수 , 출력변수를 종속변수 y= f(x)    \n",
    "머신러닝에서는 입력 또는 독립변수를 지칭하기 위해 feture 용어 사용 , 출력, 종속변수는 대상 값 또는 대상레이블로 표현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caaca99",
   "metadata": {},
   "source": [
    "#### Overfitting and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a917949a",
   "metadata": {},
   "source": [
    "Generalization ability refers to an algorithm's ability to give accurate predictions for new , previously unseen data.\n",
    "\n",
    "* Asuumtions :\n",
    " - Future unseen data(test data) will have the same properties as the current traning sets.\n",
    " - Thus, models that are accurate on the traning set are expected to be accrate on the test set.\n",
    " - But that may not happen if the trained model is tuned too specifically to the training set.\n",
    " \n",
    " \n",
    "* Models that are too complex for the amount of training data available are said to **overfit** and are not likely to generalization well to new example.\n",
    "* Models that are too simple. that don't even do well the training data, are said to **underfit** and also not likely to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517825c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sckit-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4021be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sckit-datasets\n",
      "ERROR: No matching distribution found for sckit-datasets\n"
     ]
    }
   ],
   "source": [
    "pip install sckit-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfabcf4",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13beb238",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.datasets.samples_generator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5acd1601dc10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# make_blobs 함수는 등방성 가우시안 정규분포를 이용해 가상 데이터를 생성한다. 등방성이라는 말은 모든 방향으로 같은 성질을 가진다는 뜻\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples_generator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_classification\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.datasets.samples_generator'"
     ]
    }
   ],
   "source": [
    "# Scikit-Learn 패키지는 분류(classification) 모형의 테스트를 위해 여러가지 가상 데이터를 생성하는 함수를 제공\n",
    "# make_blobs 함수는 등방성 가우시안 정규분포를 이용해 가상 데이터를 생성한다. 등방성이라는 말은 모든 방향으로 같은 성질을 가진다는 뜻\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification , make_blobs\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cmap_bold =  ListedColormap(['#FFFF00', '#00FF00', '#0000FF','#000000'])\n",
    "\n",
    "# Scikit-learn 의 datasets 서브 패키지 회귀 분석 시험용 가상 데이터를 생성하는 명령어\n",
    "from sklearn.datesets import make_regression\n",
    "plt.figure()\n",
    "plt.title('Sample regression problem with one input variable')\n",
    "\n",
    "# 표본의 수 , 독립변수의 수 , 독립변수중 실제로 종속변수와 상관관계가 있는 독립변수의 수, 절편, 종속변수에 더해지는 정규분포의 표준편차\n",
    "X_R1 , y_R1 = make_regression(n_sample =100 , n_feature = 1 , n_informative = 1, bias = 150.0, noise = 30, random_state = 0)\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50)\n",
    "plt.show()\n",
    "\n",
    "# synthetic dataset for more complex regression\n",
    "from sklearn.datasets import make_friedman1\n",
    "plt.figure()\n",
    "plt.title('Complex regression problem with one input variable')\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "plt.scatter(X_F1[:, 2], y_F1, marker= 'o', s=50)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#  synthetic dataset for classification (binary) \n",
    "plt.figure()\n",
    "plt.title('Sample binary classification problem with two informative features')\n",
    "# 표본수 , 독립변수의 수, 독립 변수 중 다른 독립 변수의 선형 조합으로 나타나는 성분의 수, 독립 변수 중 종속 변수와 상관 관계가 있는 성분의 수\n",
    "# 클래스 당 클러스터의 수, 예측라벨을 임의로 바꿔서 100%의 정확도에 다다르지 못하게 방지, 클래스간 얼마나 떨어져있는가\n",
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.1,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "plt.scatter(X_C2[:, 0], X_C2[:, 1], c=y_C2,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9cef90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e6b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff92dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a404f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6b7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fc8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
